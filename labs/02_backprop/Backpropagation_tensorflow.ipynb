{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multilayer Neural Networks in TensorFlow\n",
    "\n",
    "### Goals: \n",
    "- Auto-differentiation: the basics of `TensorFlow`\n",
    "\n",
    "### Dataset:\n",
    "- Similar as first Lab - Digits: 10 class handwritten digits\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# display figures in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(digits.images[sample_index], cmap=plt.cm.gray_r,\n",
    "           interpolation='nearest')\n",
    "plt.title(\"image label: %d\" % digits.target[sample_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Normalization\n",
    "- Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.asarray(digits.data, dtype='float32')\n",
    "target = np.asarray(digits.target, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.15, random_state=37)\n",
    "\n",
    "# mean = 0 ; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(scaler.mean_)\n",
    "# print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Implementation\n",
    "\n",
    "TensorFlow is a symbolic graph computation engine, that allows automatic differentiation of each node. Tensorflow is the default computational backend of the Keras library. I can also be used directly from Python to build deep learning models.\n",
    "\n",
    "- https://www.tensorflow.org \n",
    "- https://www.tensorflow.org/tutorials/mnist/tf/\n",
    "\n",
    "TensorFlow builds where nodes may be:\n",
    "- **constant:** constants tensors, such as a learning rate\n",
    "- **Variables:** any tensor, such as parameters of the models\n",
    "- **Placeholders:** placeholders for inputs and outputs of your models\n",
    "- many other types of nodes (functions, loss, ...)\n",
    "\n",
    "The graph is symbolic, no computation is performed until a `Session` is defined and the command `run` or `eval` is invoked. TensorFlow may run this computation on (multiple) CPUs or GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(2)\n",
    "c = tf.Variable(0)\n",
    "c = a + b\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", name=\"input\")\n",
    "Y = X + tf.constant(3.0)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(Y, feed_dict={X:2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: batches in inputs**\n",
    "- the first dimension of the input is usually kept for the batch dimension. A typical way to define an input placeholder with a 1D tensor of 128 dimensions, is:\n",
    "```\n",
    "X = tf.placeholder(\"float32\", shape=[None, 128])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Build a model using TensorFlow\n",
    "\n",
    "- Using TensorFlow, build a similar model (one hidden layer) as you previously did\n",
    "- the input will be a batch coming from X_train, and the output will be a batch of ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "\n",
    "def accuracy(y_pred, y=y_test):\n",
    "    return np.mean(np.argmax(y_pred, axis=1) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "batch_size = 32\n",
    "hid_size = 15\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 10\n",
    "\n",
    "# input and output\n",
    "X = tf.placeholder(\"float32\", shape=[None, input_size])\n",
    "y = tf.placeholder(\"int32\", shape=[None])\n",
    "\n",
    "# TODO: build the model and weights with init_weights, tf.nn.sigmoid,\n",
    "# tf.matmul and binary arithmetic operators such as +, -, * or /\n",
    "\n",
    "# TODO: build the loss, predict, and train operator\n",
    "# mock loss and b, to change.\n",
    "# Use tf.nn.sparse_softmax_cross_entropy_with_logits and\n",
    "# tf.reduce_sum\n",
    "# Note that sparse_softmax_cross_entropy_with_logits works on the\n",
    "# un-normalized logits, that is activations before the final softmax\n",
    "# layer.\n",
    "b = init_weights([output_size])\n",
    "loss = b\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# TODO: build predict node: we need to normalize the probabilities\n",
    "# with tf.nn.softmax\n",
    "predict = X\n",
    "\n",
    "# Initialization of all variables in the graph\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/tf_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    \n",
    "    losses = []\n",
    "    for e in range(num_epochs):\n",
    "        for i in range(X_train.shape[0] // batch_size):\n",
    "            # Build batches of batch_size            \n",
    "            idx, idxn = i * batch_size, min(X_train.shape[0]-1, (i+1) * batch_size)\n",
    "            batch_xs, batch_ys = X_train[idx: idxn], y_train[idx: idxn]            \n",
    "            \n",
    "            # Run train operator and monitor loss\n",
    "            _, l=sess.run([train_op, loss], feed_dict={X: batch_xs, y: batch_ys})\n",
    "            losses.append(l)\n",
    "        \n",
    "        # For each epoch, run accuracy on train and test\n",
    "        predicts_test = sess.run(predict, feed_dict={X: X_test})\n",
    "        predicts_train = sess.run(predict, feed_dict={X: X_train})\n",
    "        print(\"epoch: %d train accuracy: %0.3f test accuracy: %0.3f\"\n",
    "              % (e, accuracy(predicts_train, y_train), accuracy(predicts_test)))\n",
    "    \n",
    "    # For monitoring purposes\n",
    "    file_writer = tf.summary.FileWriter('./tensorflow_summaries', sess.graph)    \n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Exercises\n",
    "\n",
    "### Bonus:\n",
    "- add L2 regularization with $\\lambda = 10^{-4}$\n",
    "- train with arbitrary number of layers by only defining layer sizes\n",
    "- you may use tensorboard (https://www.tensorflow.org/how_tos/summaries_and_tensorboard/) to monitor loss and display graph\n",
    "- follow the official tensorflow tutorial: https://www.tensorflow.org/tutorials/mnist/tf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
