{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face verification\n",
    "\n",
    "### Goals\n",
    "- train a network for face similarity using triplet loss\n",
    "- work data augmentation, generators and hard negative mining\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- We will be using Labeled Faces in the Wild (LFW) dataset available openly at http://vis-www.cs.umass.edu/lfw/\n",
    "- For computing purposes, we'll only restrict ourselves to a subpart of the dataset. You're welcome to train on the whole dataset on GPU, by changing the PATH in the following cells, and in data download\n",
    "- We will also load pretrained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Concatenate, merge, Lambda, Dot\n",
    "from keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the dataset\n",
    "\n",
    "**This part is similar to previous notebook on siamese nets, you may just run the cells to get the necessary inputs**\n",
    "\n",
    "The dataset consists of folders corresponding to each identity. The folder name is the name of the person.\n",
    "We map each class (identity) to an integer id, and build mappings as dictionaries `name_to_classid` and `classid_to_name`\n",
    "\n",
    "Set USE_SUBSET to False if you want to use the full dataset (GPU only!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"lfw/lfw-deepfunneled/\"\n",
    "USE_SUBSET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = sorted(os.listdir(PATH))\n",
    "if USE_SUBSET:\n",
    "    dirs = dirs[:500]\n",
    "name_to_classid = {d:i for i,d in enumerate(dirs)}\n",
    "classid_to_name = {v:k for k,v in name_to_classid.items()}\n",
    "num_classes = len(name_to_classid)\n",
    "print(\"number of classes: \"+str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each directory, there is one or more images corresponding to the identity. We map each image path with an integer id, then build a few dictionaries:\n",
    "- mappings from imagepath and image id: `path_to_id` and `id_to_path`\n",
    "- mappings from class id to image ids: `classid_to_ids` and `id_to_classid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all directories\n",
    "img_paths = {c:[directory + \"/\" + img for img in sorted(os.listdir(PATH+directory))] \n",
    "             for directory,c in name_to_classid.items()}\n",
    "\n",
    "# retrieve all images\n",
    "all_images_path = []\n",
    "for img_list in img_paths.values():\n",
    "    all_images_path += img_list\n",
    "\n",
    "# map to integers\n",
    "path_to_id = {v:k for k,v in enumerate(all_images_path)}\n",
    "id_to_path = {v:k for k,v in path_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build mappings between images and class\n",
    "classid_to_ids = {k:[path_to_id[path] for path in v] for k,v in img_paths.items()}\n",
    "id_to_classid = {v:c for c,imgs in classid_to_ids.items() for v in imgs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following histogram shows the number of images per class: there are many classes with only one image. \n",
    "These classes are useful as negatives, only as we can't make a positive pair with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to compute the pairs, let's open all the possible images. It will expand all the images into RAM memory. There are more than 1000 images, so 100Mo of RAM will be used, which will not cause any issue.\n",
    "\n",
    "_Note: if you plan on opening more images, you should not open them all at once, and rather build a generator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def resize100(img):\n",
    "    return resize(img, (100, 100), preserve_range=True, mode='reflect', anti_aliasing=True)[20:80,20:80,:]\n",
    "\n",
    "def open_all_images(id_to_path):\n",
    "    all_imgs = []\n",
    "    for path in id_to_path.values():\n",
    "        all_imgs += [np.expand_dims(resize100(imread(PATH+path)),0)]\n",
    "    return np.vstack(all_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = open_all_images(id_to_path)\n",
    "mean = np.mean(all_imgs, axis=(0,1,2))\n",
    "all_imgs -= mean\n",
    "all_imgs.shape, str(all_imgs.nbytes / 1e6) + \"Mo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function builds a large number of positives/negatives pairs (train and test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet loss\n",
    "\n",
    "In the triplet loss model, we'll define 3 inputs $(a,+,-)$ for anchor, positive and negative.\n",
    "\n",
    "#### Usage and differences with siamese nets\n",
    "\n",
    "We release the hard constraint that all data of the same class should be squashed to a single point. Rather, images representation can live on a manifold, as long as they are closer to similar class images than to different class images\n",
    "\n",
    "On large datasets, with careful hyperparameters, triplets and more advances metric learning method beat siamese nets\n",
    "\n",
    "#### Outline\n",
    "\n",
    "We will build positive pairs, and find a way to sample negatives to obtain triplets\n",
    "Note that we don't need outputs anymore (positive vs negative), we're just building triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pos_pairs_for_id(classid, max_num=50):\n",
    "    imgs = classid_to_ids[classid]\n",
    "    if len(imgs) == 1:\n",
    "        return []\n",
    "    pos_pairs = [(imgs[i], imgs[j]) for i in range(len(imgs)) for j in range(i+1,len(imgs))]\n",
    "    random.shuffle(pos_pairs)\n",
    "    return pos_pairs[:max_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_positive_pairs(class_id_range):\n",
    "    listX1 = []\n",
    "    listX2 = []\n",
    "    \n",
    "    for class_id in class_id_range:\n",
    "        pos = build_pos_pairs_for_id(class_id)\n",
    "        for pair in pos:\n",
    "            listX1 += [pair[0]]\n",
    "            listX2 += [pair[1]]\n",
    "    perm = np.random.permutation(len(listX1))\n",
    "    return np.array(listX1)[perm], np.array(listX2)[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_num = int(num_classes * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa_train, Xp_train = build_positive_pairs(range(0, split_num))\n",
    "Xa_test, Xp_test = build_positive_pairs(range(split_num, num_classes-1))\n",
    "\n",
    "# Gather the ids of all images that are used for train and test\n",
    "all_img_train_idx = list(set(Xa_train) | set(Xp_train))\n",
    "all_img_test_idx = list(set(Xa_test) | set(Xp_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with 1177 different pairs, which we'll append with a random sample (as negative) in the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa_train.shape, Xp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletGenerator():\n",
    "    def __init__(self, Xa_train, Xp_train, batch_size, all_imgs, neg_imgs_idx):\n",
    "        self.cur_img_index=0\n",
    "        self.cur_img_pos_index=0\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.imgs = all_imgs\n",
    "        self.Xa = Xa_train\n",
    "        self.Xp = Xp_train\n",
    "        self.cur_train_index = 0\n",
    "        self.num_samples = Xa_train.shape[0]\n",
    "        self.neg_imgs_idx = neg_imgs_idx\n",
    "        \n",
    "    def next_train(self):\n",
    "        while 1:\n",
    "            self.cur_train_index += self.batch_size\n",
    "            if self.cur_train_index >= self.num_samples:\n",
    "                self.cur_train_index=0\n",
    "            \n",
    "            # fill one batch\n",
    "            imgs_a = self.Xa[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "            imgs_p = self.Xp[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "            imgs_n = random.sample(self.neg_imgs_idx,imgs_a.shape[0])\n",
    "            \n",
    "       # deactivate augmentation\n",
    "       #     yield ([self.imgs[imgs1], self.imgs[imgs2]],\n",
    "       #             self.Y[self.cur_train_index:self.cur_train_index+self.batch_size])\n",
    "        \n",
    "            yield ([seq.augment_images(self.imgs[imgs_a]), \n",
    "                    seq.augment_images(self.imgs[imgs_p]),\n",
    "                    seq.augment_images(self.imgs[imgs_n])\n",
    "                    ],\n",
    "                    # placeholders for output, won't be needed \n",
    "                    np.zeros(shape=(imgs_a.shape[0]))\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "gen = TripletGenerator(Xa_train, Xp_train, batch_size, all_imgs, all_img_train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_img_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[xa, xp, xn], y = next(gen.next_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.title(\"anchor\")\n",
    "    plt.imshow((xa[i] + mean) / 255)\n",
    "    plt.axis('off')\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.title(\"positive\")\n",
    "    plt.imshow((xp[i] + mean) / 255)\n",
    "    plt.axis('off')\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.title(\"negative\")\n",
    "    plt.imshow((xn[i] + mean) / 255)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_test = TripletGenerator(Xa_test, Xp_test, 32, all_imgs, all_img_test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Model\n",
    "\n",
    "The loss of the triplet model is as follows: \n",
    "\n",
    "$$ max(0, ||x_a - x_p||_2 - ||x_a - x_n||_2 + \\alpha)$$\n",
    "\n",
    "We'll be using cosine similarities instead of euclidean distances (seems to be working a bit better in that case), so the loss becomes:\n",
    "\n",
    "$$ max(0, cos(x_a, x_n) - cos(x_a - x_p) + \\alpha)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a loss which doesn't take into account the y_true, as\n",
    "# we'll be passing only 0\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "# The real loss is here\n",
    "def cosine_triplet_loss(X):\n",
    "    _alpha = 0.5\n",
    "    positive_sim, negative_sim = X\n",
    "    \n",
    "    # batch loss\n",
    "    losses = K.maximum(0.0, negative_sim - positive_sim + _alpha)\n",
    "    \n",
    "    return K.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Convolutional Network\n",
    "\n",
    "- You may as well build your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((60,60,3), dtype='float32')\n",
    "x = Conv2D(16, 3, activation=\"relu\", padding=\"same\")(inp)\n",
    "x = Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 30,30\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 15,15\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 8,8\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(40, activation=\"tanh\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64)(x)\n",
    "shared_conv2 = Model(inputs=inp, outputs = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Model\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "- Build the triplet model, using the skeleton below\n",
    "- First run the 3 inputs through the shared conv\n",
    "- Then compute positive and negative similarities\n",
    "- Then call the triplet loss function using a `Lambda` layer\n",
    "- There are other ways to do it, however Keras API is not perfect for triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = Input((60, 60, 3), name='anchor')\n",
    "positive = Input((60, 60, 3), name='positive')\n",
    "negative = Input((60, 60, 3), name='negative')\n",
    "\n",
    "# TODO\n",
    "\n",
    "pos_sim = None\n",
    "neg_sim = None\n",
    "\n",
    "loss = None\n",
    "\n",
    "model_triplet = Model(\n",
    "    inputs=[anchor, positive, negative],\n",
    "    outputs=loss)\n",
    "\n",
    "model_triplet.compile(loss=identity_loss, optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/triplet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "best_model_fname = \"triplet_checkpoint_b2.h5\"\n",
    "best_model_cb = ModelCheckpoint(best_model_fname, monitor='val_loss',\n",
    "                                save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Warning* \n",
    "- You will need to run on GPU if you're on the large dataset\n",
    "- On the small dataset, the model sometimes takes a few epochs before starting to decrease the loss\n",
    "- This can be due to the init, learning rate, or too much dropout / augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model_triplet.fit_generator(generator=gen.next_train(), \n",
    "                    steps_per_epoch=Xa_train.shape[0] // batch_size, \n",
    "                    epochs=10,\n",
    "                    validation_data = gen_test.next_train(),\n",
    "                    validation_steps=Xa_test.shape[0] // 32,\n",
    "                    callbacks=[best_model_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.ylim(0, 0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_triplet.load_weights(\"triplet_checkpoint_b2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise **\n",
    "- What do you observe? \n",
    "- Try to make changes to the model / parameters to get a better convergence\n",
    "- Try to add data augmentation, or increase the size of the training set\n",
    "- You might want to be on GPU for testing several architectures, even on the small set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may load this model\n",
    "# Trained on triplets but with larger dataset\n",
    "# Far from perfect ! \n",
    "model_triplet.load_weights(\"triplet_pretrained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = shared_conv2.predict(all_imgs)\n",
    "emb = emb / np.linalg.norm(emb, axis=-1, keepdims=True)\n",
    "pixelwise = np.reshape(all_imgs, (all_imgs.shape[0], 60*60*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(idx1,idx2):\n",
    "    return np.linalg.norm(emb[idx1] - emb[idx2])\n",
    "\n",
    "def cosine(idx1, idx2):\n",
    "    return np.dot(emb[idx1], emb[idx2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_sim(idx, topn=5, mode=\"cosine\"):\n",
    "    x = emb[idx]\n",
    "    if mode == \"cosine\":\n",
    "        x = x / np.linalg.norm(x)\n",
    "        sims = np.dot(emb, x)\n",
    "        ids = np.argsort(sims)[::-1]\n",
    "        return [(id,sims[id]) for id in ids[:topn]]\n",
    "    elif mode == \"euclidean\":\n",
    "        dists = np.linalg.norm(emb - x, axis=-1)\n",
    "        ids = np.argsort(dists)\n",
    "        return [(id,dists[id]) for id in ids[:topn]]\n",
    "    else:\n",
    "        dists = np.linalg.norm(pixelwise - pixelwise[idx], axis=-1)\n",
    "        ids = np.argsort(dists)\n",
    "        return [(id,dists[id]) for id in ids[:topn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    img = img.astype('uint8')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_classes = list(filter(lambda x: len(x[1])>4, classid_to_ids.items()))\n",
    "class_idx = random.choice(interesting_classes)[0]\n",
    "print(class_idx)\n",
    "img_idx = random.choice(classid_to_ids[class_idx])\n",
    "for id, sim in most_sim(img_idx):\n",
    "    display(all_imgs[id] + mean)\n",
    "    print((classid_to_name[id_to_classid[id]], id, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Recall@k model\n",
    "\n",
    "for each test class with > 1 image, pick image at random, and compute similarity with all other images\n",
    "compute recall @k: is the correct class within the k first images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "for class_id in range(split_num, num_classes-1):\n",
    "    img_ids = classid_to_ids[class_id]\n",
    "    if len(img_ids) > 1:\n",
    "        test_ids += img_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([len(classid_to_ids[x]) for x in list(range(split_num, num_classes-1)) if len(classid_to_ids[x])>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_k(k=10, mode=\"embedding\"):\n",
    "    num_found = 0\n",
    "    for img_idx in test_ids:\n",
    "        image_class = id_to_classid[img_idx]\n",
    "        found_classes = []\n",
    "        if mode == \"embedding\":\n",
    "            found_classes = [id_to_classid[x] for (x, score) in most_sim(img_idx, topn=k+1)[1:]]\n",
    "        elif mode == \"random\":\n",
    "            found_classes = [id_to_classid[x] for x in random.sample(\n",
    "                list(set(all_img_test_idx + all_img_train_idx) - {img_idx}), k)]\n",
    "        elif mode == \"image\":\n",
    "            found_classes = [id_to_classid[x] for (x, score) in most_sim(img_idx, topn=k+1, mode=\"image\")[1:]]\n",
    "        if image_class in found_classes:\n",
    "            num_found += 1\n",
    "    return num_found / len(test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_k(k=10), recall_k(k=10, mode=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative Mining\n",
    "\n",
    "We'll mine negatives based on previous epoch's model. To do so, we'll compute distances with all anchors, and sample among the most similar negatives, but not the too difficult ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive way to compute all similarities between all images. May be optimized!\n",
    "def build_similarities(conv, all_imgs):\n",
    "    embs = conv.predict(all_imgs)\n",
    "    embs = embs / np.linalg.norm(embs, axis=-1, keepdims=True)\n",
    "    all_sims = np.dot(embs, embs.T)\n",
    "    return all_sims\n",
    "\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "def build_negatives(anc_idxs, pos_idxs, similarities, neg_imgs_idx, num_retries=20):\n",
    "    # If no similarities were computed, return a random negative\n",
    "    if similarities is None:\n",
    "        return random.sample(neg_imgs_idx,len(anc_idxs))\n",
    "    final_neg = []\n",
    "    # for each positive pair\n",
    "    for (anc_idx, pos_idx) in zip(anc_idxs, pos_idxs):\n",
    "        anchor_class = id_to_classid[anc_idx]\n",
    "        #positive similarity\n",
    "        sim = similarities[anc_idx, pos_idx]\n",
    "        # find all negatives which are semi(hard)\n",
    "        possible_ids = np.where((similarities[anc_idx] + 0.25) > sim)[0]\n",
    "        possible_ids = intersect(neg_imgs_idx, possible_ids)\n",
    "        appended = False\n",
    "        for iteration in range(num_retries):\n",
    "            if len(possible_ids) == 0:\n",
    "                break\n",
    "            idx_neg = random.choice(possible_ids)\n",
    "            if id_to_classid[idx_neg] != anchor_class:\n",
    "                final_neg.append(idx_neg)\n",
    "                appended = True\n",
    "                break\n",
    "        if not appended:\n",
    "            final_neg.append(random.choice(neg_imgs_idx))\n",
    "    return final_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardTripletGenerator():\n",
    "    def __init__(self, Xa_train, Xp_train, batch_size, all_imgs, neg_imgs_idx, conv):\n",
    "        self.cur_img_index=0\n",
    "        self.cur_img_pos_index=0\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.imgs = all_imgs\n",
    "        self.Xa = Xa_train\n",
    "        self.Xp = Xp_train\n",
    "        self.cur_train_index = 0\n",
    "        self.num_samples = Xa_train.shape[0]\n",
    "        self.neg_imgs_idx = neg_imgs_idx\n",
    "        self.all_anchors = list(set(Xa_train))\n",
    "        self.mapping_pos = {v:k for k,v in enumerate(self.all_anchors)}\n",
    "        self.mapping_neg = {k:v for k,v in enumerate(self.neg_imgs_idx)}\n",
    "        if conv:\n",
    "            self.similarities = build_similarities(conv, self.imgs)\n",
    "        else:\n",
    "            self.similarities = None\n",
    "        \n",
    "    def next_train(self):\n",
    "        while 1:\n",
    "            self.cur_train_index += self.batch_size\n",
    "            if self.cur_train_index >= self.num_samples:\n",
    "                self.cur_train_index=0\n",
    "            \n",
    "            # fill one batch\n",
    "            imgs_a = self.Xa[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "            imgs_p = self.Xp[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "            imgs_n = build_negatives(imgs_a, imgs_p, self.similarities, self.neg_imgs_idx)\n",
    "       # deactivate augmentation\n",
    "       #     yield ([self.imgs[imgs1], self.imgs[imgs2]],\n",
    "       #             self.Y[self.cur_train_index:self.cur_train_index+self.batch_size])\n",
    "        \n",
    "            yield ([seq.augment_images(self.imgs[imgs_a]), \n",
    "                    seq.augment_images(self.imgs[imgs_p]),\n",
    "                    seq.augment_images(self.imgs[imgs_n])\n",
    "                    ],\n",
    "                    np.zeros(shape=(imgs_a.shape[0]))\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hard = HardTripletGenerator(Xa_train, Xp_train, batch_size, all_imgs, all_img_train_idx, shared_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[xa, xp, xn], y = next(gen_hard.next_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.title(\"anchor\")\n",
    "    plt.imshow((xa[i] + mean) / 255)\n",
    "    plt.axis('off')\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.title(\"positive\")\n",
    "    plt.imshow((xp[i] + mean) / 255)\n",
    "    plt.axis('off')\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.title(\"negative\")\n",
    "    plt.imshow((xn[i] + mean) / 255)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((60,60,3), dtype='float32')\n",
    "x = Conv2D(16, 3, activation=\"relu\", padding=\"same\")(inp)\n",
    "x = Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 30,30\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 15,15\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 8,8\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(50, activation=\"tanh\")(x)\n",
    "x = Dense(50)(x)\n",
    "shared_conv2 = Model(inputs=inp, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = Input((60, 60, 3), name='anchor')\n",
    "positive = Input((60, 60, 3), name='positive')\n",
    "negative = Input((60, 60, 3), name='negative')\n",
    "\n",
    "a = shared_conv2(anchor)\n",
    "p = shared_conv2(positive)\n",
    "n = shared_conv2(negative)\n",
    "\n",
    "pos_sim = Dot(axes=-1, normalize=True)([a,p])\n",
    "neg_sim = Dot(axes=-1, normalize=True)([a,n])\n",
    "\n",
    "loss = Lambda(cosine_triplet_loss,\n",
    "              output_shape=(1,))(\n",
    "             [pos_sim,neg_sim])\n",
    "\n",
    "model_triplet = Model(\n",
    "    inputs=[anchor, positive, negative],\n",
    "    outputs=loss)\n",
    "\n",
    "opt = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model_triplet.compile(loss=identity_loss, optimizer=opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_test = TripletGenerator(Xa_test, Xp_test, 32, all_imgs, all_img_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first epoch we don't generate hard triplets\n",
    "gen_hard = HardTripletGenerator(Xa_train, Xp_train, batch_size, all_imgs, all_img_train_idx, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "for epoch in range(nb_epochs):\n",
    "    print(\"built new hard generator for epoch \"+str(epoch))\n",
    "    model_triplet.fit_generator(generator=gen_hard.next_train(), \n",
    "                    steps_per_epoch=Xa_train.shape[0] // batch_size, \n",
    "                    epochs=1,\n",
    "                    validation_data = gen_test.next_train(),\n",
    "                    validation_steps=Xa_test.shape[0] // 32)\n",
    "    gen_hard = HardTripletGenerator(Xa_train, Xp_train, batch_size, all_imgs, all_img_train_idx, shared_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = shared_conv2.predict(all_imgs)\n",
    "emb = emb / np.linalg.norm(emb, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_k(k=10), recall_k(k=10, mode=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
